{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "import urllib\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranform_data(sheet):\n",
    "    data_ddf = pd.read_excel(\"treatment and control for PFE.xlsx\",sheet_name=sheet,dtype={\"symb\":np.str})\n",
    "    data_ddf[\"l1\"]=\"https://finance.yahoo.com/quote/\"\n",
    "    data_ddf[\"l2\"]=\"/history?period1=1581984000&period2=1584489600&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\"\n",
    "    data_ddf[\"link\"]= data_ddf[\"l1\"].str.cat(data_ddf.loc[:,[\"symb\",\"l2\"]])\n",
    "    data_ddf[\"Ets\"]=data_ddf[\"Ets\"].str.strip().str.capitalize()\n",
    "    return data_ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrap_data(data_ddf):\n",
    "    data = []\n",
    "    data_div=[] #For dividends\n",
    "    data_unique_ddf= data_ddf.drop_duplicates(subset=[\"Ets\",\"symb\"])\n",
    "    for _,row in pd.DataFrame.iterrows(data_unique_ddf):\n",
    "        #print(row.Ets,row.link)\n",
    "        link = row.link\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:97.0) Gecko/20100101 Firefox/97.0\"\n",
    "        }\n",
    "        response = req.get(link,headers=headers)\n",
    "        soup=BeautifulSoup(response.content,\"html.parser\")\n",
    "        tr_list = soup.find(\"tbody\").find_all(\"tr\")\n",
    "        print(row.symb,len(tr_list))\n",
    "        if len(tr_list) !=0:\n",
    "            for line in tr_list:\n",
    "                all_span = line.find_all(\"span\")\n",
    "                if all_span[-1].get_text()==\"Dividend\" :\n",
    "                    data_div.append([all_span[0].text,line.find(\"strong\").text,row.Ets])\n",
    "                else:\n",
    "                    list_values = list(map(lambda x: datetime.strptime(x.get_text(),\"%b %d, %Y\").strftime(\"%Y-%m-%d\")  if all_span.index(x)==0 else  float(x.get_text().replace(\",\",\"\"))  ,all_span))\n",
    "                    if len(list_values)!=7 :\n",
    "                        list_values.append(np.nan)\n",
    "                        print(list_values)\n",
    "                    list_values.append(row.Ets)\n",
    "                    list_values.append(len(tr_list))\n",
    "                    list_values.append(row.symb)\n",
    "                    data.append(list_values)\n",
    "    return data,data_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-2a5ef961f6fe>:2: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data_ddf = pd.read_excel(\"treatment and control for PFE.xlsx\",sheet_name=sheet,dtype={\"symb\":np.str})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jagx 21\n",
      "TTM 21\n",
      "LNVGY 21\n",
      "066570.KS 22\n",
      "['2020-03-12', 59000.0, 59000.0, 59000.0, 59000.0, 58071.42, nan]\n",
      "['2020-03-09', 60300.0, 60300.0, 60300.0, 60300.0, 59350.96, nan]\n",
      "msft 22\n",
      "NKE 22\n",
      "NTDOY 21\n",
      "VFC 22\n",
      "ANF 22\n",
      "2353.TW 20\n",
      "ADDYY 21\n",
      "ALO.PA 21\n",
      "AMZN 21\n",
      "AAPL 21\n",
      "2357.TW 20\n",
      "BMW.DE 21\n",
      "BDRBF 21\n",
      "BOSCHLTD.NS 19\n",
      "BYDDF 21\n",
      "PVH 21\n",
      "CRI 22\n",
      "TRIN 0\n",
      "000625.SZ 21\n",
      "CSCO 21\n",
      "TTDKY 21\n",
      "1766.HK 21\n",
      "DELL 21\n",
      "ELUXY 21\n",
      "2238.HK 21\n",
      "GELYF 21\n",
      "GM 22\n",
      "GOOG 21\n",
      "002241.SZ 21\n",
      "HTHIY 21\n",
      "HPQ 22\n",
      "2498.TW 20\n",
      "002502.SZ 21\n",
      "002230.SZ 21\n",
      "600100.SS 21\n",
      "PCRFY 21\n",
      "RL 21\n",
      "005930.KS 22\n",
      "['2020-03-12', 52100.0, 52100.0, 52100.0, 52100.0, 48913.69, nan]\n",
      "['2020-03-09', 56500.0, 56500.0, 56500.0, 56500.0, 53044.6, nan]\n",
      "SIEGY 21\n",
      "SKX 21\n",
      "SONY 21\n",
      "PVH 21\n",
      "FRCOY 21\n",
      "VSCO 0\n",
      "IDEXF 21\n",
      "['2020-03-11', 27.53, 27.53, 27.53, 27.53, 26.49, nan]\n",
      "['2020-03-06', 30.8, 30.8, 30.8, 30.8, 29.64, nan]\n",
      "['2020-02-27', 30.9, 30.9, 30.9, 30.9, 29.74, nan]\n",
      "['2020-02-25', 32.21, 32.21, 32.21, 32.21, 31.0, nan]\n",
      "002024.SZ 21\n",
      "ZGN 0\n",
      "ZEEL.NS 19\n",
      "SHCAY 21\n",
      "VWAGY 21\n",
      "PUM.DE 21\n",
      "ANGL.TA 19\n",
      "['2020-03-03', 5162.0, 5162.0, 5162.0, 5162.0, 5162.0, nan]\n",
      "CHMP 21\n",
      "['2020-03-17', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-16', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-13', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-12', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-11', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-10', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-09', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-06', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-05', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-04', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-03', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-03-02', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-02-28', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-02-27', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-02-26', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-02-25', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-02-24', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-02-21', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-02-20', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-02-19', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "['2020-02-18', 11.0, 11.0, 11.0, 11.0, 11.0, nan]\n",
      "LEVI 21\n",
      "0330.HK 21\n",
      "ACUR 21\n",
      "['2020-02-28', 0.28, 0.28, 0.28, 0.28, 0.28, nan]\n",
      "STLA 21\n",
      "RNO.PA 21\n",
      "TM 21\n",
      "AUDVF 21\n",
      "['2020-03-17', 1125.0, 1125.0, 1125.0, 1125.0, 1125.0, nan]\n",
      "['2020-03-16', 1125.0, 1125.0, 1125.0, 1125.0, 1125.0, nan]\n",
      "['2020-03-13', 1125.0, 1125.0, 1125.0, 1125.0, 1125.0, nan]\n",
      "['2020-03-12', 1125.0, 1125.0, 1125.0, 1125.0, 1125.0, nan]\n",
      "['2020-03-06', 1140.45, 1140.45, 1140.45, 1140.45, 1140.45, nan]\n",
      "['2020-03-05', 1140.45, 1140.45, 1140.45, 1140.45, 1140.45, nan]\n",
      "['2020-02-26', 860.9, 860.9, 860.9, 860.9, 860.9, nan]\n",
      "['2020-02-24', 903.2, 903.2, 903.2, 903.2, 903.2, nan]\n",
      "['2020-02-19', 903.55, 903.55, 903.55, 903.55, 903.55, nan]\n",
      "['2020-02-18', 903.55, 903.55, 903.55, 903.55, 903.55, nan]\n",
      "BCAUF 21\n",
      "['2020-03-13', 0.8, 0.8, 0.8, 0.8, 0.7596, nan]\n",
      "['2020-03-10', 0.81, 0.81, 0.81, 0.81, 0.7691, nan]\n",
      "['2020-03-05', 0.86, 0.86, 0.86, 0.86, 0.8166, nan]\n",
      "['2020-03-04', 0.86, 0.86, 0.86, 0.86, 0.8166, nan]\n",
      "['2020-03-02', 0.88, 0.88, 0.88, 0.88, 0.8356, nan]\n",
      "['2020-02-28', 0.88, 0.88, 0.88, 0.88, 0.8356, nan]\n",
      "['2020-02-27', 0.88, 0.88, 0.88, 0.88, 0.8356, nan]\n",
      "['2020-02-20', 0.95, 0.95, 0.95, 0.95, 0.902, nan]\n",
      "0489.HK 21\n",
      "RACE 21\n",
      "F 21\n",
      "0708.HK 21\n",
      "FB 21\n",
      "NVDA 22\n",
      "INTC 21\n",
      "TCEHY 21\n",
      "BABA 21\n",
      "ADBE 21\n",
      "VZ 21\n",
      "NTTYY 21\n",
      "DIS 21\n",
      "CRM 21\n",
      "TAM.NX 0\n",
      "MC.PA 21\n",
      "MCAP 21\n",
      "['2020-03-17', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-16', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-13', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-12', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-11', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-10', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-09', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-06', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-05', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-04', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-03', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-03-02', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-02-28', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-02-27', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-02-26', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-02-25', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-02-24', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-02-21', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-02-20', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-02-19', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "['2020-02-18', 2.0, 2.0, 2.0, 2.0, 2.0, nan]\n",
      "ABF.L 21\n",
      "HM-B.ST 21\n"
     ]
    }
   ],
   "source": [
    "sheets = [\"treatment\",\"control\"]\n",
    "for sheet in sheets :\n",
    "    data_ddf = tranform_data(sheet)\n",
    "    data,data_div = scrap_data(data_ddf)\n",
    "    bourse_ddf = pd.DataFrame(data,columns=[\"date\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\",\"ets\",\"number_date\",\"symb\"])\n",
    "    bourse_ddf.to_csv(sheet+\".csv\",index=False)\n",
    "    pd.DataFrame(data_div,columns=[\"date\",\"dividend\",\"ets\"]).to_csv(sheet+\"_div\"+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ets</th>\n",
       "      <th>number_date</th>\n",
       "      <th>symb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>1.323</td>\n",
       "      <td>1.323</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.224</td>\n",
       "      <td>1.224</td>\n",
       "      <td>31100.0</td>\n",
       "      <td>Jaguar</td>\n",
       "      <td>21</td>\n",
       "      <td>jagx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.140</td>\n",
       "      <td>1.215</td>\n",
       "      <td>1.215</td>\n",
       "      <td>53900.0</td>\n",
       "      <td>Jaguar</td>\n",
       "      <td>21</td>\n",
       "      <td>jagx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1.275</td>\n",
       "      <td>1.338</td>\n",
       "      <td>1.134</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.200</td>\n",
       "      <td>62233.0</td>\n",
       "      <td>Jaguar</td>\n",
       "      <td>21</td>\n",
       "      <td>jagx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.098</td>\n",
       "      <td>1.140</td>\n",
       "      <td>1.140</td>\n",
       "      <td>85567.0</td>\n",
       "      <td>Jaguar</td>\n",
       "      <td>21</td>\n",
       "      <td>jagx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>1.515</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.269</td>\n",
       "      <td>1.350</td>\n",
       "      <td>1.350</td>\n",
       "      <td>82433.0</td>\n",
       "      <td>Jaguar</td>\n",
       "      <td>21</td>\n",
       "      <td>jagx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   open   high    low  close  adj_close   volume     ets  \\\n",
       "0  2020-03-17  1.323  1.323  1.200  1.224      1.224  31100.0  Jaguar   \n",
       "1  2020-03-16  1.200  1.260  1.140  1.215      1.215  53900.0  Jaguar   \n",
       "2  2020-03-13  1.275  1.338  1.134  1.200      1.200  62233.0  Jaguar   \n",
       "3  2020-03-12  1.200  1.260  1.098  1.140      1.140  85567.0  Jaguar   \n",
       "4  2020-03-11  1.515  1.530  1.269  1.350      1.350  82433.0  Jaguar   \n",
       "\n",
       "   number_date  symb  \n",
       "0           21  jagx  \n",
       "1           21  jagx  \n",
       "2           21  jagx  \n",
       "3           21  jagx  \n",
       "4           21  jagx  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ddf = pd.read_csv(\"treatment.csv\")\n",
    "data_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ets</th>\n",
       "      <th>number_date</th>\n",
       "      <th>symb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>51.05</td>\n",
       "      <td>52.00</td>\n",
       "      <td>45.14</td>\n",
       "      <td>48.40</td>\n",
       "      <td>47.90</td>\n",
       "      <td>1011321.0</td>\n",
       "      <td>Puma</td>\n",
       "      <td>21</td>\n",
       "      <td>PUM.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>44.46</td>\n",
       "      <td>51.25</td>\n",
       "      <td>42.72</td>\n",
       "      <td>49.80</td>\n",
       "      <td>49.29</td>\n",
       "      <td>1299560.0</td>\n",
       "      <td>Puma</td>\n",
       "      <td>21</td>\n",
       "      <td>PUM.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>49.26</td>\n",
       "      <td>52.70</td>\n",
       "      <td>47.04</td>\n",
       "      <td>48.50</td>\n",
       "      <td>48.00</td>\n",
       "      <td>1186659.0</td>\n",
       "      <td>Puma</td>\n",
       "      <td>21</td>\n",
       "      <td>PUM.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>52.20</td>\n",
       "      <td>52.70</td>\n",
       "      <td>47.80</td>\n",
       "      <td>48.14</td>\n",
       "      <td>47.65</td>\n",
       "      <td>1066277.0</td>\n",
       "      <td>Puma</td>\n",
       "      <td>21</td>\n",
       "      <td>PUM.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>58.00</td>\n",
       "      <td>58.10</td>\n",
       "      <td>55.15</td>\n",
       "      <td>56.00</td>\n",
       "      <td>55.43</td>\n",
       "      <td>1432349.0</td>\n",
       "      <td>Puma</td>\n",
       "      <td>21</td>\n",
       "      <td>PUM.DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   open   high    low  close  adj_close     volume   ets  \\\n",
       "0  2020-03-17  51.05  52.00  45.14  48.40      47.90  1011321.0  Puma   \n",
       "1  2020-03-16  44.46  51.25  42.72  49.80      49.29  1299560.0  Puma   \n",
       "2  2020-03-13  49.26  52.70  47.04  48.50      48.00  1186659.0  Puma   \n",
       "3  2020-03-12  52.20  52.70  47.80  48.14      47.65  1066277.0  Puma   \n",
       "4  2020-03-11  58.00  58.10  55.15  56.00      55.43  1432349.0  Puma   \n",
       "\n",
       "   number_date    symb  \n",
       "0           21  PUM.DE  \n",
       "1           21  PUM.DE  \n",
       "2           21  PUM.DE  \n",
       "3           21  PUM.DE  \n",
       "4           21  PUM.DE  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ddf = pd.read_csv(\"control.csv\")\n",
    "data_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datetime.strptime(\"Mar 17, 2020\",\"%b %d, %Y\").strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-03-17'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for temporelle analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_data():\n",
    "    data_ddf=pd.DataFrame({\n",
    "        \"Ets\": [\"Addidas\",\"Calvin Klein\"],\n",
    "        \"symb\": [\"ADDYY\",\"PVH\"]\n",
    "        \n",
    "        \n",
    "    })\n",
    "    data_ddf[\"l1\"]=\"https://finance.yahoo.com/quote/\"\n",
    "    #Entre le 18/07 et le 16/08\n",
    "    data_ddf[\"l2\"]=\"/history?period1=1595030400&period2=1597536000&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\"\n",
    "    data_ddf[\"link\"]= data_ddf[\"l1\"].str.cat(data_ddf.loc[:,[\"symb\",\"l2\"]])\n",
    "    data_ddf[\"Ets\"]=data_ddf[\"Ets\"].str.strip().str.capitalize()\n",
    "    print(data_ddf)\n",
    "    data = []\n",
    "    data_div=[] #For dividends\n",
    "\n",
    "    for _,row in pd.DataFrame.iterrows(data_ddf):\n",
    "        #print(row.Ets,row.link)\n",
    "        link = row.link\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:97.0) Gecko/20100101 Firefox/97.0\"\n",
    "        }\n",
    "        response = req.get(link,headers=headers)\n",
    "        soup=BeautifulSoup(response.content,\"html.parser\")\n",
    "        tr_list = soup.find(\"tbody\").find_all(\"tr\")\n",
    "        print(row.symb,len(tr_list))\n",
    "        if len(tr_list) !=0:\n",
    "            for line in tr_list:\n",
    "                all_span = line.find_all(\"span\")\n",
    "                if all_span[-1].get_text()==\"Dividend\" :\n",
    "                    data_div.append([all_span[0].text,line.find(\"strong\").text,row.Ets])\n",
    "                else:\n",
    "                    list_values = list(map(lambda x: datetime.strptime(x.get_text(),\"%b %d, %Y\").strftime(\"%Y-%m-%d\")  if all_span.index(x)==0 else  float(x.get_text().replace(\",\",\"\"))  ,all_span))\n",
    "                    if len(list_values)!=7 :\n",
    "                        list_values.append(np.nan)\n",
    "                        print(list_values)\n",
    "                    list_values.append(row.Ets)\n",
    "                    list_values.append(len(tr_list))\n",
    "                    list_values.append(row.symb)\n",
    "                    data.append(list_values)\n",
    "    return data,data_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Ets   symb                                l1  \\\n",
      "0       Addidas  ADDYY  https://finance.yahoo.com/quote/   \n",
      "1  Calvin klein    PVH  https://finance.yahoo.com/quote/   \n",
      "\n",
      "                                                  l2  \\\n",
      "0  /history?period1=1595030400&period2=1597536000...   \n",
      "1  /history?period1=1595030400&period2=1597536000...   \n",
      "\n",
      "                                                link  \n",
      "0  https://finance.yahoo.com/quote/ADDYY/history?...  \n",
      "1  https://finance.yahoo.com/quote/PVH/history?pe...  \n",
      "ADDYY 20\n",
      "PVH 20\n"
     ]
    }
   ],
   "source": [
    "data,data_div = scrap_data()\n",
    "bourse_ddf = pd.DataFrame(data,columns=[\"date\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\",\"ets\",\"number_date\",\"symb\"])\n",
    "bourse_ddf.to_csv(\"temp.csv\",index=False)\n",
    "pd.DataFrame(data_div,columns=[\"date\",\"dividend\",\"ets\"]).to_csv(\"temp.csv_div\"+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
